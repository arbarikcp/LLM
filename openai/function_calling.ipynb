{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.12.0-cp39-cp39-macosx_12_0_arm64.whl (31.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.4 MB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.29.0,>=1.22.4 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from scipy) (1.26.4)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.12.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tenacity in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (8.2.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tiktoken in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (0.5.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: termcolor\n",
      "Successfully installed termcolor-2.4.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (1.11.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: certifi in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/bhakti/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scipy\n",
    "!pip3 install tenacity\n",
    "!pip3 install tiktoken\n",
    "!pip3 install termcolor \n",
    "!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored  \n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create few utilities \n",
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=GPT_MODEL):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n",
    "\n",
    "\n",
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    \n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            print(colored(f\"system: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            print(colored(f\"user: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['function_call']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            print(colored(f\"assistant: {message['content']}\\n\", role_to_color[message[\"role\"]]))\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            print(colored(f\"function ({message['name']}): {message['content']}\\n\", role_to_color[message[\"role\"]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets just ask the model by passing tools but not passing the required argument like location. In this case model will ask back the location. \n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n",
    "# If we prompt the model about the current weather, it will respond with some clarifying questions.\n",
    "\n",
    "# output:  ChatCompletionMessage(content='Sure, I can help you with that. Could you please provide me with your location?', role='assistant', function_call=None, tool_calls=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we provide the missing information, it will generate the appropriate function arguments for us.\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n",
    "\n",
    "# ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qOYhFO7fKaU6wpG2f1XzkDjW', function=Function(arguments='{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\"\\n}', name='get_current_weather'), type='function')])\n",
    "# it returns tool_calls, with function name and argument. Here as we ask for curreny wheather of Scotland, model retuned that we need to call \"get_current_weather\"\n",
    "\n",
    "# If we change our query like , what is the wheather in city Scotland over next X days. then model will response to call function  \"get_n_day_weather_forecast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in Glasgow, Scotland over the next x days\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n",
    "\n",
    "# output: ChatCompletionMessage(content='Sure! Please provide the number of days you would like to know the weather forecast for.', role='assistant', function_call=None, tool_calls=None)\n",
    "# As this function needs 2 parameter but we have given just 1, model is asking for another 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "chat_response.choices[0]\n",
    "# Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HwWHsNZsmkZUroPj6glmEgA5', function=Function(arguments='{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}', name='get_n_day_weather_forecast'), type='function')]), internal_metrics=[{'cached_prompt_tokens': 0, 'total_accepted_tokens': 0, 'total_batched_tokens': 269, 'total_predicted_tokens': 0, 'total_rejected_tokens': 0, 'total_tokens_in_completion': 270, 'cached_embeddings_bytes': 0, 'cached_embeddings_n': 0, 'uncached_embeddings_bytes': 0, 'uncached_embeddings_n': 0, 'fetched_embeddings_bytes': 0, 'fetched_embeddings_n': 0, 'n_evictions': 0, 'sampling_steps': 40, 'sampling_steps_with_predictions': 0, 'batcher_ttft': 0.055008649826049805, 'batcher_initial_queue_time': 0.00098419189453125}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcing the use of specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in tools_choice parameter we can set which functions to use. \n",
    "\n",
    "# in this cell we force the model to use get_n_day_weather_forecast\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools, tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_n_day_weather_forecast\"}}\n",
    ")\n",
    "chat_response.choices[0].message\n",
    "\n",
    "#ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_240XQedt4Gi8VZsUwOvFpQfZ', function=Function(arguments='{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 1\\n}', name='get_n_day_weather_forecast'), type='function')])\n",
    "\n",
    "# Here although this is not most appropriate function to call for this Query, but we are forcing model to use it by tool_choice param."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcing not to use any functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by setting tool_choice=\"none\" even if we passed tools param, it will not return in tool_calls param in response. \n",
    "# But as we have passed tools argument, it will return the appropriate function argument as json \n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me the current weather (use Celcius) for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools, tool_choice=\"none\"\n",
    ")\n",
    "chat_response.choices[0].message\n",
    "\n",
    "# ChatCompletionMessage(content='{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\"\\n}', role='assistant', function_call=None, tool_calls=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newer models like gpt-4-1106-preview or gpt-3.5-turbo-1106 can call multiple functions in one turn.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
